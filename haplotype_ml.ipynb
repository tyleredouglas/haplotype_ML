{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Estimating genome-wide haplotype frequencies using LightGBM "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Overall workflow:\n",
        "\n",
        "1) Generate simulated populations with recombination/drift with simulate_population. Takes as input a matrix of genotypes at fixed intervals for population founders (each column is a population).\n",
        "2) Calculate true haplotype frequencies in simulated populations for model training with get_true_freqs\n",
        "3) Generate simulated NGS data from populations with generate_reads\n",
        "4) Map reads, call SNPs in populations and founder lines\n",
        "5) Define genomic windows and identify true haplotype frequency per window with either define_windows or define_by_SNPs\n",
        "6) Train model using observed SNP frequencies and true haplotype frequencies per window \n",
        "7) Evaluate model performance, visualize predicted/true frequencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#have to run python 3.10 for now, biopython does not yet support 3.13\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import pysam\n",
        "from Bio import SeqIO\n",
        "import random\n",
        "from itertools import combinations\n",
        "import matplotlib.pyplot as plt\n",
        "import lightgbm as lgb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.read_csv('/Users/tyler/Desktop/haplotype_ML/chr3L_RILs_updated.csv')\n",
        "df = pd.DataFrame(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#set RILs to df columns\n",
        "df_wide = df.pivot_table(index=['CHROM', 'pos'], columns='sample', values='fHap', aggfunc='first')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_wide.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# recombination function to be used in simulate_population\n",
        "# function to simulate population w/drift\n",
        "# determines true haplotype frequency in simulated population\n",
        "\n",
        "class Chromosome:\n",
        "    def __init__(self, genotype):\n",
        "        self.genotype = genotype\n",
        "\n",
        "    @staticmethod\n",
        "    def recombine(chrom1, chrom2):\n",
        "        import random\n",
        "        recombination_point = random.randrange(0, len(chrom1.genotype) - 1)  # Choose a point for crossover\n",
        "        \n",
        "        new_chrom1 = pd.concat([\n",
        "            chrom1.genotype.iloc[:recombination_point],\n",
        "            chrom2.genotype.iloc[recombination_point:]\n",
        "        ])\n",
        "        new_chrom2 = pd.concat([\n",
        "            chrom2.genotype.iloc[:recombination_point],\n",
        "            chrom1.genotype.iloc[recombination_point:]\n",
        "        ])\n",
        "        return Chromosome(new_chrom1), Chromosome(new_chrom2)\n",
        "\n",
        "class Population:\n",
        "    def __init__(self, ril_matrix, population_size):\n",
        "        import random\n",
        "        self.ril_matrix = ril_matrix\n",
        "        self.population_size = population_size\n",
        "        self.chromosomes = [\n",
        "            Chromosome(ril_matrix.iloc[:, idx])\n",
        "            for idx in np.random.choice(ril_matrix.shape[1], population_size * 2, replace=True)\n",
        "        ]\n",
        "\n",
        "    def simulate_generation(self, recombination_rate):\n",
        "        import random\n",
        "        new_chromosomes = []\n",
        "        for _ in range(self.population_size):\n",
        "            parent1, parent2 = random.sample(self.chromosomes, 2)\n",
        "\n",
        "            if random.random() < recombination_rate:\n",
        "                offspring1, offspring2 = Chromosome.recombine(parent1, parent2)\n",
        "            else:\n",
        "                offspring1 = Chromosome(parent1.genotype.copy())\n",
        "                offspring2 = Chromosome(parent2.genotype.copy())\n",
        "\n",
        "            new_chromosomes.extend([offspring1, offspring2])\n",
        "\n",
        "        # Apply genetic drift by random sampling\n",
        "        self.chromosomes = random.choices(new_chromosomes, k=self.population_size * 2)\n",
        "\n",
        "    def simulate_generations(self, n_generations, recombination_rate):\n",
        "        for generation in range(n_generations):\n",
        "            self.simulate_generation(recombination_rate)\n",
        "\n",
        "    def get_population_matrix(self):\n",
        "        return pd.concat([chrom.genotype for chrom in self.chromosomes], axis=1)\n",
        "\n",
        "class Simulation:\n",
        "    def __init__(self, ril_matrix, n_flies, n_generations, recombination_rate):\n",
        "        self.population = Population(ril_matrix, n_flies)\n",
        "        self.n_generations = n_generations\n",
        "        self.recombination_rate = recombination_rate\n",
        "\n",
        "    def run(self):\n",
        "        self.population.simulate_generations(self.n_generations, self.recombination_rate)\n",
        "        return self.population.get_population_matrix()\n",
        "\n",
        "    def calculate_haplotype_frequencies(self):\n",
        "        simulated_pop = self.population.get_population_matrix()\n",
        "        haplotype_columns = simulated_pop.columns.difference(['sample', 'CHROM', 'pos'])\n",
        "        haplotype_counts = simulated_pop[haplotype_columns].apply(lambda x: x.value_counts(), axis=1).fillna(0)\n",
        "        haplotype_frequencies = haplotype_counts.div(haplotype_counts.sum(axis=1), axis=0)\n",
        "        return haplotype_frequencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#coordinates to simulated PE reads, adjust average read length as desired\n",
        "#generate reverse complement for PE2\n",
        "#should be one fasta file per chromosome, each containing  all the full set of template sequences (i.e. founder chromosomes)\n",
        "#outputs PE reads\n",
        "\n",
        "class GenomeSimulator:\n",
        "    def __init__(self, fasta_files, chromosomes):\n",
        "        self.chromosome_dict = {}\n",
        "        for chrom in chromosomes:\n",
        "            self.chromosome_dict[chrom] = {}\n",
        "            for record in SeqIO.parse(fasta_files[chrom], \"fasta\"):\n",
        "                haplotype_id = record.id\n",
        "                self.chromosome_dict[chrom][haplotype_id] = record.seq\n",
        "        self.chromosomes = chromosomes\n",
        "\n",
        "    def _reverse_complement(self, seq):\n",
        "        complement = {'A': 'T', 'T': 'A', 'C': 'G', 'G': 'C'}\n",
        "        return ''.join(complement.get(base, base) for base in reversed(seq))\n",
        "\n",
        "    def _read_coordinates(self, population, chroms):\n",
        "        read_length_f = np.round(np.random.normal(loc=150, scale=10)).astype(int)\n",
        "        read_length_r = np.round(np.random.normal(loc=150, scale=10)).astype(int)\n",
        "        fragment = np.round(np.random.normal(loc=500, scale=50)).astype(int)\n",
        "        gap = fragment - (read_length_f + read_length_r)\n",
        "\n",
        "        chromosome = np.random.choice(chroms, replace=True)\n",
        "        chrom_of_interest = population.loc[chromosome]\n",
        "        max_pos = chrom_of_interest.index.max()\n",
        "\n",
        "        read_start_f = np.random.randint(1, max_pos - 2000)\n",
        "        read_end_f = read_start_f + read_length_f\n",
        "        read_end_r = read_end_f + gap\n",
        "        read_start_r = read_end_r + read_length_r\n",
        "\n",
        "        return chromosome, read_start_f, read_end_f, read_length_f, read_start_r, read_end_r, read_length_r\n",
        "\n",
        "    def generate_paired_end_reads(self, population, read_num, out_name):\n",
        "        #store number of reads generated per haplotype per position (read depth)\n",
        "        haplotype_counts = pd.DataFrame(0, index=population.index, columns=['B1','B2','B3','B4','B5','B6','B7','B8'])\n",
        "\n",
        "        read_count = 0\n",
        "        chrom_list = list(self.chromosome_dict.keys())\n",
        "\n",
        "        with open(f'{out_name}_1.fastq', 'w') as fastq_file1, open(f'{out_name}_2.fastq', 'w') as fastq_file2:\n",
        "            while read_count < read_num:\n",
        "                chrom, start_f, end_f, length_f, start_r, end_r, length_r = self._read_coordinates(population, chrom_list)\n",
        "                chrom_of_interest = population.loc[chrom]\n",
        "                template = chrom_of_interest.iloc[:, np.random.randint(1, chrom_of_interest.shape[1])]\n",
        "                nearest_pos = min(template.index, key=lambda x: abs(x - start_f))\n",
        "                haplotype = template[nearest_pos]\n",
        "                fasta_seqs = self.chromosome_dict[chrom]\n",
        "                haplotype_sequence = fasta_seqs[haplotype]\n",
        "\n",
        "                forward_read = haplotype_sequence[start_f:end_f]\n",
        "                reverse_read = haplotype_sequence[end_r:start_r]\n",
        "                reverse_read = self._reverse_complement(reverse_read)\n",
        "                reverse_read = reverse_read[::-1]\n",
        "\n",
        "                haplotype_counts.at[(chrom, nearest_pos), haplotype] += 1\n",
        "                read_count += 1\n",
        "                read_ID = np.random.randint(1000, 9999)\n",
        "\n",
        "                read_quality_f = 'I'*len(forward_read)\n",
        "                fastq_file1.write(f'@{chrom}_{start_f}_{read_ID}/1\\n')\n",
        "                fastq_file1.write(f'{forward_read}\\n')\n",
        "                fastq_file1.write('+\\n')\n",
        "                fastq_file1.write(f'{read_quality_f}\\n')\n",
        "\n",
        "                read_quality_r = 'I'*len(reverse_read)\n",
        "                fastq_file2.write(f'@{chrom}_{start_f}_{read_ID}/2\\n')\n",
        "                fastq_file2.write(f'{reverse_read}\\n')\n",
        "                fastq_file2.write('+\\n')\n",
        "                fastq_file2.write(f'{read_quality_r}\\n')\n",
        "\n",
        "        return haplotype_counts, fastq_file1, fastq_file2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#same as before, but sets window size based on SNP number or by actual window length\n",
        "#store the window and corresponding true_freqs row in dictionary\n",
        "#these replaced define_windows and define_by_SNPs\n",
        "\n",
        "def define_windows(observed_frequencies, true_frequencies, window, step, sim):\n",
        "    results = {}\n",
        "    for window_start in range(observed_frequencies['pos'].min(), observed_frequencies['pos'].max() - window, step):\n",
        "        window_end = window_start + window\n",
        "        window_data = observed_frequencies[(observed_frequencies['pos'] >= window_start) & (observed_frequencies['pos'] < window_end)]\n",
        "\n",
        "        #minimum number of SNPs per window\n",
        "        if window_data.shape[0] > 20:\n",
        "            middle_obs = window_data['pos'].median()\n",
        "            window_data = window_data.iloc[:, 2:11]\n",
        "            window_data = window_data.reset_index(drop=True)\n",
        "            middle_true = min(true_frequencies['pos'], key=lambda x: abs(x - middle_obs))\n",
        "            window_true_freq = true_frequencies[true_frequencies['pos'] == middle_true].iloc[:, 2:10]\n",
        "            window_true_freq = window_true_freq.reset_index(drop=True)\n",
        "            results[str(sim), (str(window_start), str(window_end))] = {'window': window_data, 'true_freq_row': window_true_freq}\n",
        "    return results\n",
        "\n",
        "def define_by_SNPs(observed_frequencies, true_frequencies, snp_number, step, sim):\n",
        "    results = {}\n",
        "    window_start = 0\n",
        "    window_end = window_start + snp_number\n",
        "\n",
        "    while window_end < observed_frequencies.index.max():\n",
        "        window_data = observed_frequencies.iloc[window_start:window_end, :]\n",
        "        middle_obs = window_data['pos'].median()\n",
        "        window_data = window_data.iloc[:, 2:11]\n",
        "        window_data = window_data.reset_index(drop=True)\n",
        "        middle_true = min(true_frequencies['pos'], key=lambda x: abs(x - middle_obs))\n",
        "        window_true_freq = true_frequencies[true_frequencies['pos'] == middle_true].iloc[:, 2:10]\n",
        "        window_true_freq = window_true_freq.reset_index(drop=True)\n",
        "\n",
        "        results[str(sim), (str(observed_frequencies.iloc[window_start]['pos']), str(observed_frequencies.iloc[window_end]['pos']))] = {\n",
        "            'window': window_data,\n",
        "            'true_freq_row': window_true_freq\n",
        "        }\n",
        "        window_start += step\n",
        "        window_end += step\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#store founder fastas for each chromosome \n",
        "founders_3L = None # read_fasta handled in GenomeSimulator now\n",
        "\n",
        "#list of chromosomes to sample (including only 3L for now)\n",
        "chroms = ['chr3L']\n",
        "\n",
        "#dict so that the correct haplotype can be called from a randomly selected chromosome by read_coordinates\n",
        "chromosome_dict = None  # we replaced this with GenomeSimulator class\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setting simulation parameters and generating reads:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_flies = 300  # population size\n",
        "n_generations = 15  # number of generations\n",
        "recombination_rate = 0.5  # probability of recombination occurring\n",
        "read_num = 500000 # when generating data for chr3L only this simulates ~100X read depth\n",
        "num_sims = 100 # number of populations to create"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# i ran this from the cluster due to memory constraints, took ~8 hours to simulate data for 100 populations. \n",
        "# see scripts folder on github for slurm and python scripts adapted for the cluster\n",
        "\n",
        "fasta_files = {'chr3L': '/Users/tyler/Desktop/haplotype_ml/founder_fastas/B.3L.fasta'}\n",
        "genome_simulator = GenomeSimulator(fasta_files, chroms)\n",
        "\n",
        "for i in range(1, num_sims + 1):\n",
        "    sim_name = f'sim{i}'\n",
        "    sim_populator = Simulation(df_wide, n_flies, n_generations, recombination_rate)\n",
        "    sim_pop = sim_populator.run()\n",
        "    true_freqs = sim_populator.calculate_haplotype_frequencies()\n",
        "    read_depth, fq1, fq2 = genome_simulator.generate_paired_end_reads(sim_pop, read_num, sim_name)\n",
        "    read_depth.to_csv(f'{sim_name}_depth.csv', index = True)\n",
        "    true_freqs.to_csv(f'{sim_name}_true_freqs.csv', index = True)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Running simulation from cluster, then mapping reads and calling SNPs, calculating SNP frequencies. \n",
        "\n",
        "```\n",
        "#! /bin/bash\n",
        "# Job name:\n",
        "#SBATCH --job-name=simul_100\n",
        "#\n",
        "# Account:\n",
        "#SBATCH --account=fc_poison\n",
        "#\n",
        "# Partition:\n",
        "#SBATCH --partition=savio3\n",
        "#\n",
        "# Wall clock limit:\n",
        "#SBATCH --time=48:00:00\n",
        "#\n",
        "## Command(s) to run:\n",
        "source activate lgbm3.1  \n",
        "python -c \"import pysam\"\n",
        "python -c \"import pandas as pd\" \n",
        "python -c \"import numpy as np\"\n",
        "python -c \"from Bio import SeqIO\"\n",
        "python simul_100.py\n",
        "\n",
        "module load bwa\n",
        "module load samtools\n",
        "module load bcftools\n",
        "\n",
        "for file in *_1.fastq; do\n",
        "    name=$(echo $file | sed 's/_1.fastq//')\n",
        "    file2=\"${name}_2.fastq\"                \n",
        "    bwa mem -t 20 -M dmel_r6.fna \"$file\" \"$file2\" | samtools sort -@ 20 -o \"${name}.sorted.bam\"  # Align and sort\n",
        "    samtools index -@ 20 \"${name}.sorted.bam\"  \n",
        "done\n",
        "\n",
        "bcftools mpileup -I -q 0 -Q 0 --threads 20 -t NT_037436.4 -a \"FORMAT/AD,FORMAT/DP\" -f dmel_r6.fna -b bam_names.txt -o sim100_mpile.txt\n",
        "\n",
        "bcftools call --threads 20 sim100_mpile.txt -mv -Ov > sim100.vcf \n",
        "\n",
        "bcftools query -e 'GT =\"./.\"' -e'QUAL<60' -f'%CHROM %POS %REF %ALT [ %AD{0} %AD{1}] [%GT]\\n' sim100.vcf | sed 's/NT_037436.4/chr3L/' | grep -v '\\.' | perl /global/home/users/tylerdouglas/modules/tdlong/accuracy.freqtab.pl > simul_100_freqs.txt\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#set column names for observed frequencies table\n",
        "col_names = ['chrom', 'pos', 'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8']\n",
        "\n",
        "for i in range(1, num_sims + 1):\n",
        "    sim_name = f'sim{i}'\n",
        "    col_names.append(sim_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#first 10 columns are chromosome, position, and presence/absence of each SNP in the 8 founders. \n",
        "#the rest of the columns are SNP frequency in each of the 100 simulated populations\n",
        "SNP_freqs = pd.read_csv('/Users/tyler/Desktop/haplotype_ML/simul_100_freqs.csv', names = col_names, header = None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#initialize dictionary to store genomic windows/true frequencies per window\n",
        "input_windows = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#define windows, find true frequencies for that window, store in input_windows\n",
        "for i in range(1, num_sims + 1):\n",
        "\n",
        "    sim_name = f'sim{i}'\n",
        "    true_freqs = pd.read_csv(f'/Users/tyler/Desktop/haplotype_ml/{sim_name}_true_freqs.csv')    #read true freqs table\n",
        "    obs_freqs = SNP_freqs[['chrom', 'pos', 'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', sim_name]].copy()    #create df of founders + current sim\n",
        "    obs_freqs['pos'] = obs_freqs['pos'].round(-3)\n",
        "    print(\"processing windows for:\", sim_name) \n",
        "    windows = define_windows(obs_freqs, true_freqs, 200000, 20000, sim_name) #both window functions work on one sim population at a time\n",
        "    #windows = define_by_SNPs(obs_freqs, true_freqs, 200, 20, sim_name)\n",
        "    input_windows.update(windows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#number of windows\n",
        "print(len(input_windows))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#lgbm performed poorly with just flattening SNP window, so generating summary statistics of each window to pass to lgbm instead\n",
        "#gets counts of each haplotype per window, as well as the average frequency of SNPs that that haplotype contains \n",
        "#idea would be that if a haplotype is widespread and generally contains high frequency SNPs, it itself might be represented at a high frequency\n",
        "\n",
        "def summarise_window(df_window):\n",
        "   \n",
        "    feats = {}\n",
        "    sim_name = df_window.columns[-1]\n",
        "\n",
        "    #count haplotype occurence per window, mean freq of SNPs present in that haplotype\n",
        "    for haplotype in ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8']:\n",
        "\n",
        "        feats[f'{haplotype}_count'] = df_window[haplotype].sum()\n",
        "        feats[f'{haplotype}_mean_freq_present'] = df_window.loc[df_window[haplotype] == 1, sim_name].mean()\n",
        "    \n",
        "    for key in feats:\n",
        "        if np.isnan(feats[key]):\n",
        "            feats[key] = 0.0\n",
        "    \n",
        "    return feats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#generate feature/label arrays to pass to lgbm\n",
        "\n",
        "X_data_agg = []\n",
        "y_data = []\n",
        "\n",
        "for key, value in input_windows.items():\n",
        "\n",
        "    df_window = value['window']  \n",
        "    sim_name, (start_pos, end_pos) = key\n",
        "    feats = summarise_window(df_window) #get haplotype count and mean SNP freq of SNPs the haplotype contains\n",
        "    feats['sim_name'] = sim_name\n",
        "    feats['window_start'] = start_pos\n",
        "    feats['window_end'] = end_pos\n",
        "\n",
        "    freq_dict = value['true_freq_row'].values.flatten() #get true frequencies for the window\n",
        "\n",
        "    #add window haplotype statistics and true haplotype frequencies to features and labels array\n",
        "    y_data.append(freq_dict)\n",
        "    X_data_agg.append(feats)\n",
        "\n",
        "X_data_agg_df = pd.DataFrame(X_data_agg)  \n",
        "y_data = np.array(y_data) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#separate out sim number and genomic position so that it isn't passed to the model, but retain later for visualization\n",
        "pos_cols = ['sim_name', 'window_start', 'window_end']\n",
        "feature_cols = [c for c in X_data_agg_df.columns if c not in pos_cols]\n",
        "X_features = X_data_agg_df[feature_cols].copy()\n",
        "pos_df = X_data_agg_df[pos_cols].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#model performs marginally better when I include interactions between haplotypes, adding them to features array\n",
        "from itertools import combinations\n",
        "columns = [f'B{i}_count' for i in range(1, 9)]\n",
        "for col1, col2 in combinations(columns, 2):\n",
        "    X_features[f'interaction_{col1}_{col2}'] = X_features[col1] * X_features[col2]\n",
        "\n",
        "X_features['mean_SNP_presence'] = X_features[[f'B{i}_mean_freq_present' for i in range(1, 9)]].mean(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#generate training and validation data\n",
        "X_train, X_test, y_train, y_test, pos_train, pos_test = train_test_split(\n",
        "    X_features,   \n",
        "    y_data,\n",
        "    pos_df,       \n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(X_train.head(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#define the model, wrap in MultiOutputRegressor\n",
        "lgb_reg = lgb.LGBMRegressor(\n",
        "    n_estimators=2000,\n",
        "    learning_rate=0.05,\n",
        "    num_leaves=64,\n",
        "    lambda_l1=0.1,\n",
        "    lambda_l2=0.2,\n",
        "    objective='regression',\n",
        "    min_data_in_leaf=5,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "multi_lgb = MultiOutputRegressor(lgb_reg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "multi_lgb.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = multi_lgb.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#model is most noisy for very low haplotype frequencies, rounding all frequencies below 0.3% to zero, can experiment with what the threshold should be\n",
        "threshold = 0.008\n",
        "y_pred_thresholded = np.clip(y_pred, 0, None)\n",
        "y_pred_thresholded[y_pred_thresholded < threshold] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# gives metrics on model performance\n",
        "def evaluate_multioutput(y_true, y_predicted):\n",
        "    mae = mean_absolute_error(y_true, y_predicted)\n",
        "    mse = mean_squared_error(y_true, y_predicted)\n",
        "    r2 = r2_score(y_true, y_predicted, multioutput='uniform_average')\n",
        "    print(\"Evaluation Metrics:\")\n",
        "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "    print(f\"R² Score: {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#check performance with and without thresholding minimum frequency\n",
        "evaluate_multioutput(y_test, y_pred)\n",
        "print(\"----\")\n",
        "evaluate_multioutput(y_test, y_pred_thresholded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#format and save predicted frequencies for each genomic window for visualization\n",
        "results_df = pos_test.copy()\n",
        "haplotypes = ['B1','B2','B3','B4','B5','B6','B7','B8']\n",
        "\n",
        "for i, hap in enumerate(haplotypes):\n",
        "    results_df[f'pred_{hap}'] = y_pred_thresholded[:, i]\n",
        "    results_df[f'true_{hap}'] = y_test[:, i]\n",
        "\n",
        "print(results_df.head(5))\n",
        "results_df.to_csv(\"lgb_200kb_thresholded.csv\", index=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing model performance  with ggplot\n",
        "\n",
        "```\n",
        "library(ggplot2)\n",
        "library(dplyr)\n",
        "library(tidyr)\n",
        "library(cowplot)\n",
        "library(scales)\n",
        "\n",
        "df <- read.csv(\"lgb_200kb_thresholded.csv\")\n",
        "\n",
        "df_ae <- df %>%\n",
        "  pivot_longer(\n",
        "    cols = starts_with(\"pred_\") | starts_with(\"true_\"), \n",
        "    names_to = c(\".value\", \"founder\"),                      \n",
        "    names_sep = \"_\"                                    \n",
        "  ) \n",
        "\n",
        "df_ae$ae <- abs(df_ae$true - df_long$pred)\n",
        "\n",
        "mae <- df_ae %>%\n",
        "  group_by(sim_name, founder) %>%\n",
        "  summarise(mae = mean(ae), r2 = 1 - (sum((true - pred)^2) / sum((true - mean(true))^2))) %>%\n",
        "  mutate(annotation = sprintf(\"MAE: %.3f\\nR²: %.3f\", mae, r2))\n",
        "\n",
        "df_plot <- df %>%\n",
        "  pivot_longer(\n",
        "    cols = starts_with(\"pred_\") | starts_with(\"true_\"), \n",
        "    names_to = c(\"type\", \"founder\"),                         \n",
        "    names_sep = \"_\",\n",
        "    values_to = \"freq\"\n",
        "  )\n",
        "\n",
        "mae_sim <- subset(mae, sim_name == 'sim89')\n",
        "\n",
        "ggplot(data = subset(df_plot, sim_name == 'sim89'),\n",
        "       aes(x = window_start, y = freq, group = type, color = type)) +\n",
        "  geom_line(alpha = 0.7) +\n",
        "  facet_wrap(~founder) +\n",
        "  geom_text(data = mae_sim, \n",
        "            aes(x = Inf, y = Inf, label = annotation), \n",
        "            inherit.aes = FALSE, \n",
        "            hjust = 1.1, vjust = 1.1, \n",
        "            size = 3, color = \"black\") +\n",
        "  scale_color_manual(values = c(\"#000080\", \"#93E1D8\")) +\n",
        "  theme_cowplot(font_size = 12) +\n",
        "  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n",
        "  scale_x_continuous(\n",
        "    breaks = pretty_breaks(n = 5),\n",
        "    labels = function(x) paste0(x / 1e6, \"Mbp\")\n",
        "  ) +\n",
        "  labs(x = \"Genomic Position (Mbp)\", y = \"Frequency\")\n",
        "  theme(\n",
        "    axis.text.x = element_text(angle = 45, hjust = 1),\n",
        "    strip.text = element_text(size = 10),\n",
        "    panel.spacing = unit(1, \"lines\")\n",
        "  )\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
