{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating genome-wide haplotype frequencies using LightGBM "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall workflow:\n",
    "\n",
    "1) Generate simulated populations with recombination/drift with simulate_population. Takes as input a matrix of genotypes at fixed intervals for population founders (each column is a population).\n",
    "2) Calculate true haplotype frequencies in simulated populations for model training with get_true_freqs\n",
    "3) Generate simulated NGS data from populations with generate_reads\n",
    "4) Map reads, call SNPs in populations and founder lines\n",
    "5) Define genomic windows and identify true haplotype frequency per window with either define_windows or define_by_SNPs\n",
    "6) Train model using observed SNP frequencies and true haplotype frequencies per window \n",
    "7) Evaluate model performance, visualize predicted/true frequencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have to run python 3.10 for now, biopython does not yet support 3.13\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pysam\n",
    "from Bio import SeqIO\n",
    "import random\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load RIL genotype data and pivot to wide format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/tyler/Desktop/haplotype_ML/chr3L_RILs_updated.csv')\n",
    "df = pd.DataFrame(data)\n",
    "#set RILs to df columns\n",
    "df_wide = df.pivot_table(index=['CHROM', 'pos'], columns='sample', values='fHap', aggfunc='first')\n",
    "df_wide.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing the old `recombine`, `simulate_population`, and `get_true_freqs` with updated, optimized classes\n",
    "\n",
    "Below is the new **Chromosome**, **Population**, **Simulation** structure, which handles recombination, population simulation, and true haplotype frequency calculation, preserving the logic of the old code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recombination function to be used in simulate_population\n",
    "# function to simulate population w/drift\n",
    "# determines true haplotype frequency in simulated population\n",
    "\n",
    "import random\n",
    "\n",
    "class Chromosome:\n",
    "    def __init__(self, genotype):\n",
    "        self.genotype = genotype\n",
    "\n",
    "    @staticmethod\n",
    "    def recombine(chrom1, chrom2):\n",
    "        # randomly select a recombination point (window) between the chromosomes at 10,000bp interval\n",
    "        recombination_point = random.randrange(0, len(chrom1.genotype) - 1)\n",
    "        \n",
    "        # create the offspring chromosome with recombination\n",
    "        new_chrom1 = pd.concat([\n",
    "            chrom1.genotype.iloc[:recombination_point],\n",
    "            chrom2.genotype.iloc[recombination_point:]\n",
    "        ])\n",
    "        new_chrom2 = pd.concat([\n",
    "            chrom2.genotype.iloc[:recombination_point],\n",
    "            chrom1.genotype.iloc[recombination_point:]\n",
    "        ])\n",
    "        \n",
    "        return Chromosome(new_chrom1), Chromosome(new_chrom2)\n",
    "\n",
    "class Population:\n",
    "    def __init__(self, ril_matrix, population_size):\n",
    "        self.ril_matrix = ril_matrix\n",
    "        self.population_size = population_size\n",
    "        # Initiate starting population\n",
    "        self.chromosomes = [\n",
    "            Chromosome(ril_matrix.iloc[:, idx])\n",
    "            for idx in np.random.choice(ril_matrix.shape[1], population_size * 2, replace=True)\n",
    "        ]\n",
    "\n",
    "    def simulate_generation(self, recombination_rate):\n",
    "        new_chromosomes = []\n",
    "        for _ in range(self.population_size):\n",
    "            parent1, parent2 = random.sample(self.chromosomes, 2)\n",
    "            \n",
    "            if random.random() < recombination_rate:\n",
    "                offspring1, offspring2 = Chromosome.recombine(parent1, parent2)\n",
    "            else:\n",
    "                # no recombination, copy parents\n",
    "                offspring1, offspring2 = Chromosome(parent1.genotype.copy()), Chromosome(parent2.genotype.copy())\n",
    "            \n",
    "            new_chromosomes.extend([offspring1, offspring2])\n",
    "\n",
    "        # drift by random sampling\n",
    "        self.chromosomes = random.choices(new_chromosomes, k=self.population_size * 2)\n",
    "\n",
    "    def simulate_generations(self, n_generations, recombination_rate):\n",
    "        for generation in range(n_generations):\n",
    "            self.simulate_generation(recombination_rate)\n",
    "\n",
    "    def get_population_matrix(self):\n",
    "        return pd.concat([chrom.genotype for chrom in self.chromosomes], axis=1)\n",
    "\n",
    "class Simulation:\n",
    "    def __init__(self, ril_matrix, n_flies, n_generations, recombination_rate):\n",
    "        self.population = Population(ril_matrix, n_flies)\n",
    "        self.n_generations = n_generations\n",
    "        self.recombination_rate = recombination_rate\n",
    "\n",
    "    def run(self):\n",
    "        # simulate population with drift/recombination\n",
    "        self.population.simulate_generations(self.n_generations, self.recombination_rate)\n",
    "        return self.population.get_population_matrix()\n",
    "\n",
    "    def calculate_haplotype_frequencies(self):\n",
    "        # calculates haplotype frequencies in simulated population\n",
    "        simulated_pop = self.population.get_population_matrix()\n",
    "        haplotype_columns = simulated_pop.columns.difference(['sample', 'CHROM', 'pos'])\n",
    "        haplotype_counts = simulated_pop[haplotype_columns].apply(lambda x: x.value_counts(), axis=1).fillna(0)\n",
    "        haplotype_frequencies = haplotype_counts.div(haplotype_counts.sum(axis=1), axis=0)\n",
    "        return haplotype_frequencies\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing the old read_fasta, read_coordinates, reverse_complement, generate_reads with the new `GenomeSimulator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should be one fasta file per chromosome, each containing  all the full set of template sequences (i.e. founder chromosomes)\n",
    "#coordinates to simulated PE reads, adjust average read length as desired\n",
    "#generate reverse complement for PE2\n",
    "#outputs PE reads\n",
    "\n",
    "class GenomeSimulator:\n",
    "    def __init__(self, fasta_files, chromosomes):\n",
    "        # store founder fastas for each chromosome\n",
    "        self.chromosome_dict = {\n",
    "            chrom: self._read_fasta(fasta_files[chrom]) for chrom in chromosomes\n",
    "        }\n",
    "        self.chromosomes = chromosomes\n",
    "\n",
    "    @staticmethod\n",
    "    def _read_fasta(file_path):\n",
    "        sequences = {}\n",
    "        for record in SeqIO.parse(file_path, \"fasta\"):\n",
    "            haplotype_id = record.id\n",
    "            sequences[haplotype_id] = record.seq\n",
    "        return sequences\n",
    "\n",
    "    def _reverse_complement(self, seq):\n",
    "        complement = {'A': 'T', 'T': 'A', 'C': 'G', 'G': 'C'}\n",
    "        return ''.join(complement.get(base, base) for base in reversed(seq))\n",
    "\n",
    "    def _read_coordinates(self, population, chroms):\n",
    "        # get read length from normal distribution\n",
    "        read_length_f = np.round((np.random.normal(loc=150, scale=10))).astype(int)\n",
    "        read_length_r = np.round((np.random.normal(loc=150, scale=10))).astype(int)\n",
    "\n",
    "        # library fragment length and inner distance\n",
    "        fragment = np.round((np.random.normal(loc=500, scale=50))).astype(int)\n",
    "        gap = fragment - (read_length_f + read_length_r)\n",
    "\n",
    "        # select chromosome to read\n",
    "        chromosome = np.random.choice(chroms, replace=True)\n",
    "        chrom_of_interest = population.loc[chromosome]\n",
    "        max_pos = chrom_of_interest.index.max()\n",
    "\n",
    "        # define read boundaries\n",
    "        read_start_f = np.random.randint(1, max_pos - 2000)\n",
    "        read_end_f = read_start_f + read_length_f\n",
    "        read_end_r = read_end_f + gap\n",
    "        read_start_r = read_end_r + read_length_r\n",
    "\n",
    "        return chromosome, read_start_f, read_end_f, read_length_f, read_start_r, read_end_r, read_length_r\n",
    "\n",
    "    def generate_paired_end_reads(self, population, read_num, out_name):\n",
    "        # store number of reads generated per haplotype per position (read depth)\n",
    "        haplotype_counts = pd.DataFrame(0, index=population.index, columns=['B1','B2','B3','B4','B5','B6','B7','B8'])\n",
    "\n",
    "        read_count = 0\n",
    "        chrom_list = list(self.chromosome_dict.keys())\n",
    "\n",
    "        # initialize empty fastq files\n",
    "        with open(f'{out_name}_1.fastq', 'w') as fastq_file1, open(f'{out_name}_2.fastq', 'w') as fastq_file2:\n",
    "\n",
    "            while read_count < read_num:\n",
    "                # randomly define read coordinates\n",
    "                chrom, start_f, end_f, length_f, start_r, end_r, length_r = self._read_coordinates(population, chrom_list)\n",
    "\n",
    "                # subset population dataframe to chromosome where read is\n",
    "                chrom_of_interest = population.loc[chrom]\n",
    "\n",
    "                # pick random chromosome to sequence\n",
    "                template = chrom_of_interest.iloc[:, np.random.randint(1, chrom_of_interest.shape[1])]\n",
    "\n",
    "                # get haplotype at position nearest to read location\n",
    "                nearest_pos = min(template.index, key=lambda x: abs(x - start_f))\n",
    "                haplotype = template[nearest_pos]\n",
    "\n",
    "                # generate read\n",
    "                fasta_seqs = self.chromosome_dict[chrom]\n",
    "                haplotype_sequence = fasta_seqs[haplotype]\n",
    "\n",
    "                forward_read = haplotype_sequence[start_f:end_f]\n",
    "                reverse_read = haplotype_sequence[end_r:start_r]\n",
    "                reverse_read = self._reverse_complement(reverse_read)\n",
    "                reverse_read = reverse_read[::-1]  # flip reverse the sequence\n",
    "\n",
    "                # track reads per haplotype\n",
    "                haplotype_counts.at[(chrom, nearest_pos), haplotype] += 1\n",
    "                read_count += 1\n",
    "                read_ID = np.random.randint(1000, 9999)\n",
    "\n",
    "                # write read to fastq file:\n",
    "                read_quality_f = 'I' * len(forward_read)\n",
    "                fastq_file1.write(f'@{chrom}_{start_f}_{read_ID}/1\\n')\n",
    "                fastq_file1.write(f'{forward_read}\\n')\n",
    "                fastq_file1.write('+\\n')\n",
    "                fastq_file1.write(f'{read_quality_f}\\n')\n",
    "\n",
    "                read_quality_r = 'I' * len(reverse_read)\n",
    "                fastq_file2.write(f'@{chrom}_{start_f}_{read_ID}/2\\n')\n",
    "                fastq_file2.write(f'{reverse_read}\\n')\n",
    "                fastq_file2.write('+\\n')\n",
    "                fastq_file2.write(f'{read_quality_r}\\n')\n",
    "\n",
    "        return haplotype_counts, fastq_file1, fastq_file2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining genomic windows with either window size or number of SNPs\n",
    "Below we replace `define_windows` and `define_by_SNPs` with a refactored `GenomicWindow` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns dictionary where key = genomic position of window start/end and values: \n",
    "#window: 9 x N matrix (N = number of snps) and true_freqs (true haplotype frequencies of that window)\n",
    "#just like the old define_windows and define_by_SNPs, but neatly wrapped in a class with 2 methods\n",
    "\n",
    "class GenomicWindow:\n",
    "    def __init__(self, observed_frequencies, true_frequencies):\n",
    "        self.observed_frequencies = observed_frequencies\n",
    "        self.true_frequencies = true_frequencies\n",
    "\n",
    "    def define_windows(self, window, step, sim):\n",
    "        # define windows by physical size\n",
    "        results = {}\n",
    "        for window_start in range(self.observed_frequencies['pos'].min(), \n",
    "                                  self.observed_frequencies['pos'].max() - window, step):\n",
    "            window_end = window_start + window\n",
    "            window_data = self.observed_frequencies[\n",
    "                (self.observed_frequencies['pos'] >= window_start) & \n",
    "                (self.observed_frequencies['pos'] < window_end)\n",
    "            ]\n",
    "            #minimum number of SNPs per window\n",
    "            if window_data.shape[0] > 20:\n",
    "                middle_obs = window_data['pos'].median()\n",
    "                window_data_trimmed = window_data.iloc[:, 2:11].reset_index(drop=True)\n",
    "                middle_true = min(self.true_frequencies['pos'], key=lambda x: abs(x - middle_obs))\n",
    "                window_true_freq = self.true_frequencies[self.true_frequencies['pos'] == middle_true].iloc[:, 2:10].reset_index(drop=True)\n",
    "                results[str(sim), (str(window_start), str(window_end))] = {\n",
    "                    'window': window_data_trimmed,\n",
    "                    'true_freq_row': window_true_freq\n",
    "                }\n",
    "        return results\n",
    "\n",
    "    def define_by_SNPs(self, snp_number, step, sim):\n",
    "        # define windows by SNP count\n",
    "        results = {}\n",
    "        window_start = 0\n",
    "        window_end = window_start + snp_number\n",
    "\n",
    "        while window_end < self.observed_frequencies.index.max():\n",
    "            window_data = self.observed_frequencies.iloc[window_start:window_end, :]\n",
    "            middle_obs = window_data['pos'].median()\n",
    "            window_data_trimmed = window_data.iloc[:, 2:11].reset_index(drop=True)\n",
    "            middle_true = min(self.true_frequencies['pos'], key=lambda x: abs(x - middle_obs))\n",
    "            window_true_freq = self.true_frequencies[self.true_frequencies['pos'] == middle_true].iloc[:, 2:10].reset_index(drop=True)\n",
    "            results[\n",
    "                str(sim), (\n",
    "                    str(self.observed_frequencies.iloc[window_start]['pos']), \n",
    "                    str(self.observed_frequencies.iloc[window_end]['pos'])\n",
    "                )\n",
    "            ] = {\n",
    "                'window': window_data_trimmed,\n",
    "                'true_freq_row': window_true_freq\n",
    "            }\n",
    "            window_start += step\n",
    "            window_end += step\n",
    "        return results\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting simulation parameters and generating reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_flies = 300  # population size\n",
    "n_generations = 15  # number of generations\n",
    "recombination_rate = 0.5  # probability of recombination occurring\n",
    "read_num = 500000 # when generating data for chr3L only this simulates ~100X read depth\n",
    "num_sims = 100 # number of populations to create\n",
    "\n",
    "# list of chromosomes to sample (including only 3L for now, will add the other pending genotyping data)\n",
    "chroms = ['chr3L']\n",
    "\n",
    "# dict so that the correct haplotype can be called from a randomly selected chromosome by read_coordinates\n",
    "# (Now embedded in GenomeSimulator)\n",
    "fasta_files = {\n",
    "    'chr3L': '/Users/tyler/Desktop/haplotype_ml/founder_fastas/B.3L.fasta'\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the simulation for multiple populations, generating reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_simulator = GenomeSimulator(fasta_files, chroms)\n",
    "\n",
    "for i in range(1, num_sims + 1):\n",
    "    sim_name = f'sim{i}'\n",
    "    \n",
    "    # simulate population\n",
    "    sim = Simulation(df_wide, n_flies, n_generations, recombination_rate)\n",
    "    sim_pop = sim.run()\n",
    "    true_freqs = sim.calculate_haplotype_frequencies()\n",
    "\n",
    "    # generate reads\n",
    "    read_depth, fq1, fq2 = genome_simulator.generate_paired_end_reads(sim_pop, read_num, sim_name)\n",
    "    read_depth.to_csv(f'{sim_name}_depth.csv', index=True)\n",
    "    true_freqs.to_csv(f'{sim_name}_true_freqs.csv', index=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of calling SNP frequencies and defining genomic windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample code to parse SNP calls (SNP_freqs), define windows, etc.\n",
    "# in practice you'd do bcftools or similar to generate a .csv of SNP frequencies\n",
    "\n",
    "col_names = ['chrom', 'pos', 'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8']\n",
    "for i in range(1, num_sims + 1):\n",
    "    sim_name = f'sim{i}'\n",
    "    col_names.append(sim_name)\n",
    "\n",
    "# hypothetical example:\n",
    "# SNP_freqs = pd.read_csv('sim100_freqs.csv', names=col_names, header=None)\n",
    "# input_windows = {}\n",
    "# for i in range(1, num_sims+1):\n",
    "#     sname = f'sim{i}'\n",
    "#     true_freqs = pd.read_csv(f'{sname}_true_freqs.csv')\n",
    "#     obs_freqs = SNP_freqs[['chrom','pos','B1','B2','B3','B4','B5','B6','B7','B8', sname]].copy()\n",
    "#     obs_freqs['pos'] = obs_freqs['pos'].round(-3)\n",
    "#     gw = GenomicWindow(obs_freqs, true_freqs)\n",
    "#     windows = gw.define_windows(200000, 20000, sname)\n",
    "#     input_windows.update(windows)\n",
    "# len(input_windows)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training example using LightGBM (unchanged)\n",
    "Below is your original model training pipeline, referencing `input_windows` as prepared above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rest of your original ML training code remains unchanged.\n",
    "# For instance:\n",
    "\n",
    "# X_data_agg = []\n",
    "# y_data = []\n",
    "# for key, value in input_windows.items():\n",
    "#     # etc.\n",
    "#     pass\n",
    "\n",
    "print(\"Notebook has replaced old scripts with updated classes. Ready for end-to-end workflow.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconverter_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
